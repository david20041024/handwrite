{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "X_train = np.load(\"x.npy\")\n",
        "y_train = np.array([1]*1000+[0]*1000, dtype=\"float32\")\n",
        "\n",
        "# 1. 資料增強函數\n",
        "def augment_matrix(mat):\n",
        "\n",
        "    mat = np.array(mat)\n",
        "\n",
        "\n",
        "    # 隨機平移 (-1, 0, 1)\n",
        "    def shift_matrix(mat, dx, dy):\n",
        "        mat_shifted = np.zeros_like(mat)\n",
        "        x_range = range(max(0, dx), min(8, 8+dx))\n",
        "        y_range = range(max(0, dy), min(8, 8+dy))\n",
        "        x_new_range = range(max(0, -dx), min(8, 8-dx))\n",
        "        y_new_range = range(max(0, -dy), min(8, 8-dy))\n",
        "        mat_shifted[np.ix_(y_new_range, x_new_range)] = mat[np.ix_(y_range, x_range)]\n",
        "        return mat_shifted\n",
        "\n",
        "    # 隨機旋轉 (0°, 90°, 180°, 270°)\n",
        "    def rotate_matrix(mat, k):\n",
        "        return np.rot90(mat, k)\n",
        "\n",
        "    #\n",
        "    def flip_matrix(mat, axis):\n",
        "        return np.flip(mat, axis)\n",
        "\n",
        "    augmented_mats = []\n",
        "\n",
        "    # 原始矩陣\n",
        "    augmented_mats.append(mat)\n",
        "\n",
        "    # 平移增强\n",
        "    for dx in [-1, 0, 1]:\n",
        "        for dy in [-1, 0, 1]:\n",
        "            if dx != 0 or dy != 0:\n",
        "                augmented_mats.append(shift_matrix(mat, dx, dy))\n",
        "\n",
        "    # 旋转增强\n",
        "    for k in range(1, 4):  # 90°, 180°, 270°\n",
        "        augmented_mats.append(rotate_matrix(mat, k))\n",
        "\n",
        "    # 旋轉增強\n",
        "    augmented_mats.append(flip_matrix(mat, 0))  # 水平翻转\n",
        "    augmented_mats.append(flip_matrix(mat, 1))  # 垂直翻转\n",
        "\n",
        "    # 添加噪音\n",
        "    noisy_mat = mat.copy()\n",
        "    noise_mask = np.random.random((8, 8)) < 0.1\n",
        "    noisy_mat[noise_mask] = 1 - noisy_mat[noise_mask]\n",
        "    augmented_mats.append(noisy_mat)\n",
        "\n",
        "    return augmented_mats\n",
        "\n",
        "\n",
        "def expand_dataset(X, y, target_size=10000):\n",
        "    \"\"\"将数据集扩展到目标大小\"\"\"\n",
        "    n_original = len(X)\n",
        "    if n_original >= target_size:\n",
        "        return X, y\n",
        "\n",
        "    X_expanded = []\n",
        "    y_expanded = []\n",
        "\n",
        "\n",
        "    augmentations_per_sample = target_size // n_original + 1\n",
        "\n",
        "    for i in range(n_original):\n",
        "        original_mat = X[i]\n",
        "        original_label = y[i]\n",
        "\n",
        "        # 為每個樣本產生多個增強版本\n",
        "        augmented_versions = augment_matrix(original_mat)\n",
        "\n",
        "        selected_augmentations = augmented_versions[:min(augmentations_per_sample, len(augmented_versions))]\n",
        "\n",
        "        for aug_mat in selected_augmentations:\n",
        "            X_expanded.append(aug_mat)\n",
        "            y_expanded.append(original_label)\n",
        "\n",
        "    while len(X_expanded) < target_size:\n",
        "        idx = np.random.randint(0, n_original)\n",
        "        X_expanded.append(X[idx])\n",
        "        y_expanded.append(y[idx])\n",
        "\n",
        "    X_expanded = np.array(X_expanded[:target_size])\n",
        "    y_expanded = np.array(y_expanded[:target_size])\n",
        "\n",
        "\n",
        "    # 打亂數據\n",
        "    indices = np.random.permutation(len(X_expanded))\n",
        "    X_expanded = X_expanded[indices]\n",
        "    y_expanded = y_expanded[indices]\n",
        "\n",
        "    return X_expanded, y_expanded\n",
        "\n",
        "\n",
        "X_train_expanded, y_train_expanded = expand_dataset(X_train, y_train, target_size=10000)\n",
        "print(f\"扩展后数据集大小: {len(X_train_expanded)} 样本\")\n",
        "\n",
        "def data_generator(X, y, batch_size=32):\n",
        "    n_samples = len(X)\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    while True:\n",
        "        for start_idx in range(0, n_samples, batch_size):\n",
        "            end_idx = min(start_idx + batch_size, n_samples)\n",
        "            batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "            batch_X = X[batch_indices]\n",
        "            batch_y = y[batch_indices]\n",
        "\n",
        "            yield batch_X, batch_y\n",
        "\n",
        "# 4. 建構模型\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(8, 8)),\n",
        "    Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', 'precision', 'recall']\n",
        ")\n",
        "\n",
        "# 5. 回呼函數\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
        "]\n",
        "\n",
        "# 6. 劃分訓練集和驗證集\n",
        "split_idx = int(0.8 * len(X_train_expanded))\n",
        "X_train_final = X_train_expanded[:split_idx]\n",
        "y_train_final = y_train_expanded[:split_idx]\n",
        "X_val = X_train_expanded[split_idx:]\n",
        "y_val = y_train_expanded[split_idx:]\n",
        "\n",
        "# 7. 訓練模型\n",
        "batch_size = 32\n",
        "steps_per_epoch = len(X_train_final) // batch_size\n",
        "\n",
        "history = model.fit(\n",
        "    data_generator(X_train_final, y_train_final, batch_size=batch_size),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=150,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "val_loss, val_accuracy, val_precision, val_recall = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"\\n验证集结果:\")\n",
        "print(f\"准确率: {val_accuracy:.4f}\")\n",
        "print(f\"精确率: {val_precision:.4f}\")\n",
        "print(f\"召回率: {val_recall:.4f}\")\n",
        "\n",
        "# 8. 修改後的預測函數 - 大於0.5就顯示為1\n",
        "def predict_number(input_matrix):\n",
        "    data = np.array(input_matrix).reshape(1, 8, 8).astype(\"float32\")\n",
        "    pred = model.predict(data, verbose=0)[0][0]\n",
        "\n",
        "    if pred > 0.5:\n",
        "        confidence = \"（是1）\"\n",
        "        judgment = '1'\n",
        "    else:\n",
        "        confidence = \"（不是1）\"\n",
        "        judgment = '3'\n",
        "\n",
        "    print(f\"预测概率: {pred:.4f}{confidence} -> 判断: {judgment}\")\n",
        "    return pred, judgment\n",
        "\n",
        "sample_input1 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "#1\n",
        "sample_input2 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,1,1,0,0,0],\n",
        "[0,0,0,0,1,0,0,0],\n",
        "[0,0,0,0,1,0,0,0],\n",
        "[0,0,0,0,1,0,0,0],\n",
        "[0,0,0,0,1,0,0,0],\n",
        "[0,0,1,1,1,1,1,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "#1\n",
        "sample_input3 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,1,0,0,0,0,0],\n",
        "[0,1,1,0,0,0,0,0],\n",
        "[0,0,1,0,0,0,0,0],\n",
        "[0,0,1,0,0,0,0,0],\n",
        "[0,1,1,1,1,0,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "#1\n",
        "sample_input4 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,1,0,0,0,0,0],\n",
        "[0,1,1,0,0,0,0,0],\n",
        "[0,0,1,0,0,0,0,0],\n",
        "[0,0,1,1,0,0,0,0],\n",
        "[0,0,1,1,1,1,1,0],\n",
        "[1,1,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "#1\n",
        "sample_input5 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "\n",
        "sample_input6 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,1,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,0,1,1,1],\n",
        "[0,0,0,0,1,1,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "\n",
        "sample_input7 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,1,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,1,1,1],\n",
        "[0,1,1,1,1,0,0,0]\n",
        "]\n",
        "sample_input8 = [\n",
        "[0,0,0,0,0,1,1,0],\n",
        "[0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,1,0,0,1,0,0,0],\n",
        "[0,0,1,1,1,0,0,0],\n",
        "[0,0,0,1,1,1,0,0],\n",
        "[0,0,0,0,0,1,1,0]\n",
        "]\n",
        "sample_input9 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,1,0,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "sample_input10 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,1,0,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "\n",
        "sample_input11 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,1,1,1,1,0,0],\n",
        "[0,0,1,0,0,1,0,0],\n",
        "[0,0,0,1,1,0,0,0],\n",
        "[0,0,1,1,1,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,1,0,0,0],\n",
        "[0,0,1,1,0,0,0,0]\n",
        "]\n",
        "#1\n",
        "sample_input12 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,1,1,1,0,0,0],\n",
        "[0,0,0,0,1,0,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,1,1,1,0,0,0],\n",
        "[0,0,0,0,1,0,0,0],\n",
        "[0,1,1,1,1,0,0,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "#1\n",
        "sample_input13 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,1,1,1,0],\n",
        "[0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,0,1,1,0],\n",
        "[0,0,0,0,0,1,1,1],\n",
        "[0,0,0,0,0,0,0,1],\n",
        "[0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,0,1,0,0]\n",
        "]\n",
        "#1\n",
        "sample_input14 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,1,1,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0],\n",
        "[0,1,1,1,0,0,0,0],\n",
        "[0,1,1,1,0,0,0,0],\n",
        "[0,0,1,1,0,0,0,0],\n",
        "[0,1,1,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0]\n",
        "]\n",
        "#1\n",
        "sample_input15 = [\n",
        "[0,1,1,1,1,0,0,0],\n",
        "[0,1,0,0,0,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,1,1,1,1,1,0],\n",
        "[0,0,0,0,0,0,1,1],\n",
        "[0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,1,1,0,0],\n",
        "[0,1,1,1,0,0,0,0]\n",
        "]\n",
        "\n",
        "sample_input16 = [\n",
        "[0,0,0,0,1,0,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,1,1,1,0,1,0,0],\n",
        "[1,0,0,1,1,0,1,0],\n",
        "[1,1,0,0,1,1,0,0],\n",
        "[0,1,0,0,0,0,0,0],\n",
        "[0,0,1,0,0,0,0,0],\n",
        "[0,0,1,1,0,0,0,0]\n",
        "]\n",
        "\n",
        "sample_input17 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,1,1,1,1,0,0,0],\n",
        "[0,1,0,0,1,1,0,0],\n",
        "[0,0,0,0,1,1,0,0],\n",
        "[0,0,1,1,1,0,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,1,0,0,1,0,0,0],\n",
        "[0,0,1,1,1,0,0,0]\n",
        "]\n",
        "sample_input18 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,1,1,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,1,1,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,1,1,0,0,0],\n",
        "[1,1,1,1,0,0,0,0]\n",
        "]\n",
        "sample_input19 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,1,1,0,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,1,1,0,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,1,1,0,0],\n",
        "[1,1,1,1,0,0,0,0]\n",
        "]\n",
        "sample_input20 = [\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0],\n",
        "[0,0,1,1,1,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,1,1,1,0,0],\n",
        "[0,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,1,0,0,0]\n",
        "]\n",
        "\n",
        "predict_number(sample_input1)\n",
        "predict_number(sample_input2)\n",
        "predict_number(sample_input3)\n",
        "predict_number(sample_input4)\n",
        "predict_number(sample_input5)\n",
        "predict_number(sample_input6)\n",
        "predict_number(sample_input7)\n",
        "predict_number(sample_input8)\n",
        "predict_number(sample_input9)\n",
        "predict_number(sample_input10)\n",
        "predict_number(sample_input11)\n",
        "predict_number(sample_input12)\n",
        "predict_number(sample_input13)\n",
        "predict_number(sample_input14)\n",
        "predict_number(sample_input15)\n",
        "predict_number(sample_input16)\n",
        "predict_number(sample_input17)\n",
        "predict_number(sample_input18)\n",
        "predict_number(sample_input19)\n",
        "predict_number(sample_input20)\n",
        "model.save('model.h5')\n",
        "\n",
        "files.download('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WHZ-QIjdzF0e",
        "outputId": "deeae90e-a315-49b1-f665-298715836102"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b3b765a-c71e-4ac9-9dcc-23261fe1c8a0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b3b765a-c71e-4ac9-9dcc-23261fe1c8a0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving x.npy to x (5).npy\n",
            "扩展后数据集大小: 10000 样本\n",
            "Epoch 1/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5380 - loss: 0.9328 - precision: 0.7007 - recall: 0.3849 - val_accuracy: 0.7005 - val_loss: 0.6825 - val_precision: 0.6820 - val_recall: 0.9320 - learning_rate: 5.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.7059 - precision: 0.7146 - recall: 0.7828 - val_accuracy: 0.7305 - val_loss: 0.6278 - val_precision: 0.7119 - val_recall: 0.9203 - learning_rate: 5.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7200 - loss: 0.6532 - precision: 0.7393 - recall: 0.8198 - val_accuracy: 0.7620 - val_loss: 0.5848 - val_precision: 0.7393 - val_recall: 0.9279 - learning_rate: 5.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7420 - loss: 0.6154 - precision: 0.7553 - recall: 0.8395 - val_accuracy: 0.7855 - val_loss: 0.5473 - val_precision: 0.7593 - val_recall: 0.9371 - learning_rate: 5.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7529 - loss: 0.5875 - precision: 0.7693 - recall: 0.8369 - val_accuracy: 0.8040 - val_loss: 0.5158 - val_precision: 0.7778 - val_recall: 0.9396 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7743 - loss: 0.5637 - precision: 0.7871 - recall: 0.8524 - val_accuracy: 0.8190 - val_loss: 0.4835 - val_precision: 0.7969 - val_recall: 0.9346 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7881 - loss: 0.5409 - precision: 0.8011 - recall: 0.8579 - val_accuracy: 0.8360 - val_loss: 0.4579 - val_precision: 0.8149 - val_recall: 0.9379 - learning_rate: 5.0000e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.5170 - precision: 0.8118 - recall: 0.8709 - val_accuracy: 0.8510 - val_loss: 0.4308 - val_precision: 0.8292 - val_recall: 0.9446 - learning_rate: 5.0000e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.4785 - precision: 0.8343 - recall: 0.8794 - val_accuracy: 0.8650 - val_loss: 0.4040 - val_precision: 0.8503 - val_recall: 0.9388 - learning_rate: 5.0000e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8343 - loss: 0.4586 - precision: 0.8449 - recall: 0.8849 - val_accuracy: 0.8695 - val_loss: 0.3847 - val_precision: 0.8497 - val_recall: 0.9488 - learning_rate: 5.0000e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8475 - loss: 0.4359 - precision: 0.8563 - recall: 0.8947 - val_accuracy: 0.8740 - val_loss: 0.3678 - val_precision: 0.8593 - val_recall: 0.9430 - learning_rate: 5.0000e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.4253 - precision: 0.8563 - recall: 0.8958 - val_accuracy: 0.8870 - val_loss: 0.3545 - val_precision: 0.8744 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.4135 - precision: 0.8677 - recall: 0.9008 - val_accuracy: 0.8875 - val_loss: 0.3417 - val_precision: 0.8774 - val_recall: 0.9430 - learning_rate: 5.0000e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.4036 - precision: 0.8634 - recall: 0.9019 - val_accuracy: 0.8905 - val_loss: 0.3318 - val_precision: 0.8846 - val_recall: 0.9388 - learning_rate: 5.0000e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3967 - precision: 0.8708 - recall: 0.8958 - val_accuracy: 0.8975 - val_loss: 0.3221 - val_precision: 0.8920 - val_recall: 0.9421 - learning_rate: 5.0000e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.3610 - precision: 0.8905 - recall: 0.9133 - val_accuracy: 0.9010 - val_loss: 0.3148 - val_precision: 0.8913 - val_recall: 0.9497 - learning_rate: 5.0000e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.3488 - precision: 0.8908 - recall: 0.9232 - val_accuracy: 0.9045 - val_loss: 0.3085 - val_precision: 0.8969 - val_recall: 0.9488 - learning_rate: 5.0000e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.3441 - precision: 0.8944 - recall: 0.9197 - val_accuracy: 0.9065 - val_loss: 0.3005 - val_precision: 0.9004 - val_recall: 0.9480 - learning_rate: 5.0000e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.3416 - precision: 0.8901 - recall: 0.9157 - val_accuracy: 0.9035 - val_loss: 0.2979 - val_precision: 0.8974 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.3359 - precision: 0.8916 - recall: 0.9278 - val_accuracy: 0.9110 - val_loss: 0.2898 - val_precision: 0.9056 - val_recall: 0.9497 - learning_rate: 5.0000e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8970 - loss: 0.3288 - precision: 0.9039 - recall: 0.9259 - val_accuracy: 0.9100 - val_loss: 0.2853 - val_precision: 0.9114 - val_recall: 0.9404 - learning_rate: 5.0000e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.3112 - precision: 0.9088 - recall: 0.9248 - val_accuracy: 0.9170 - val_loss: 0.2811 - val_precision: 0.9157 - val_recall: 0.9480 - learning_rate: 5.0000e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.3049 - precision: 0.9025 - recall: 0.9304 - val_accuracy: 0.9160 - val_loss: 0.2806 - val_precision: 0.9149 - val_recall: 0.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.3021 - precision: 0.9048 - recall: 0.9306 - val_accuracy: 0.9140 - val_loss: 0.2748 - val_precision: 0.9126 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 25/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.2984 - precision: 0.9045 - recall: 0.9307 - val_accuracy: 0.9185 - val_loss: 0.2712 - val_precision: 0.9186 - val_recall: 0.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 26/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9104 - loss: 0.2861 - precision: 0.9153 - recall: 0.9366 - val_accuracy: 0.9155 - val_loss: 0.2676 - val_precision: 0.9182 - val_recall: 0.9421 - learning_rate: 5.0000e-04\n",
            "Epoch 27/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2796 - precision: 0.9162 - recall: 0.9307 - val_accuracy: 0.9200 - val_loss: 0.2625 - val_precision: 0.9230 - val_recall: 0.9446 - learning_rate: 5.0000e-04\n",
            "Epoch 28/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2828 - precision: 0.9162 - recall: 0.9310 - val_accuracy: 0.9215 - val_loss: 0.2577 - val_precision: 0.9245 - val_recall: 0.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.2808 - precision: 0.9170 - recall: 0.9318 - val_accuracy: 0.9205 - val_loss: 0.2584 - val_precision: 0.9182 - val_recall: 0.9513 - learning_rate: 5.0000e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2738 - precision: 0.9145 - recall: 0.9399 - val_accuracy: 0.9170 - val_loss: 0.2585 - val_precision: 0.9171 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2648 - precision: 0.9206 - recall: 0.9328 - val_accuracy: 0.9180 - val_loss: 0.2506 - val_precision: 0.9248 - val_recall: 0.9388 - learning_rate: 5.0000e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2646 - precision: 0.9215 - recall: 0.9284 - val_accuracy: 0.9185 - val_loss: 0.2509 - val_precision: 0.9193 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2532 - precision: 0.9297 - recall: 0.9410 - val_accuracy: 0.9200 - val_loss: 0.2456 - val_precision: 0.9230 - val_recall: 0.9446 - learning_rate: 5.0000e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2539 - precision: 0.9245 - recall: 0.9405 - val_accuracy: 0.9235 - val_loss: 0.2364 - val_precision: 0.9262 - val_recall: 0.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2516 - precision: 0.9222 - recall: 0.9401 - val_accuracy: 0.9205 - val_loss: 0.2425 - val_precision: 0.9189 - val_recall: 0.9505 - learning_rate: 5.0000e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2394 - precision: 0.9320 - recall: 0.9440 - val_accuracy: 0.9230 - val_loss: 0.2368 - val_precision: 0.9289 - val_recall: 0.9430 - learning_rate: 5.0000e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2431 - precision: 0.9269 - recall: 0.9458 - val_accuracy: 0.9225 - val_loss: 0.2373 - val_precision: 0.9260 - val_recall: 0.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2401 - precision: 0.9293 - recall: 0.9420 - val_accuracy: 0.9195 - val_loss: 0.2386 - val_precision: 0.9236 - val_recall: 0.9430 - learning_rate: 5.0000e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2494 - precision: 0.9246 - recall: 0.9387 - val_accuracy: 0.9165 - val_loss: 0.2418 - val_precision: 0.9232 - val_recall: 0.9379 - learning_rate: 5.0000e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.2386 - precision: 0.9312 - recall: 0.9487 - val_accuracy: 0.9165 - val_loss: 0.2401 - val_precision: 0.9197 - val_recall: 0.9421 - learning_rate: 5.0000e-04\n",
            "Epoch 41/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9202 - loss: 0.2413 - precision: 0.9241 - recall: 0.9439 - val_accuracy: 0.9200 - val_loss: 0.2380 - val_precision: 0.9216 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 42/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2312 - precision: 0.9293 - recall: 0.9433 - val_accuracy: 0.9225 - val_loss: 0.2363 - val_precision: 0.9332 - val_recall: 0.9371 - learning_rate: 5.0000e-04\n",
            "Epoch 43/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.2235 - precision: 0.9382 - recall: 0.9476 - val_accuracy: 0.9205 - val_loss: 0.2354 - val_precision: 0.9272 - val_recall: 0.9404 - learning_rate: 5.0000e-04\n",
            "Epoch 44/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.2286 - precision: 0.9363 - recall: 0.9456 - val_accuracy: 0.9235 - val_loss: 0.2311 - val_precision: 0.9326 - val_recall: 0.9396 - learning_rate: 5.0000e-04\n",
            "Epoch 45/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2251 - precision: 0.9353 - recall: 0.9494 - val_accuracy: 0.9255 - val_loss: 0.2354 - val_precision: 0.9292 - val_recall: 0.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 46/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.2278 - precision: 0.9347 - recall: 0.9479 - val_accuracy: 0.9230 - val_loss: 0.2374 - val_precision: 0.9226 - val_recall: 0.9505 - learning_rate: 5.0000e-04\n",
            "Epoch 47/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.2146 - precision: 0.9408 - recall: 0.9506 - val_accuracy: 0.9145 - val_loss: 0.2405 - val_precision: 0.9202 - val_recall: 0.9379 - learning_rate: 5.0000e-04\n",
            "Epoch 48/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.2244 - precision: 0.9356 - recall: 0.9484 - val_accuracy: 0.9225 - val_loss: 0.2306 - val_precision: 0.9289 - val_recall: 0.9421 - learning_rate: 5.0000e-04\n",
            "Epoch 49/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9321 - loss: 0.2145 - precision: 0.9396 - recall: 0.9472 - val_accuracy: 0.9185 - val_loss: 0.2325 - val_precision: 0.9214 - val_recall: 0.9438 - learning_rate: 5.0000e-04\n",
            "Epoch 50/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.2161 - precision: 0.9402 - recall: 0.9537 - val_accuracy: 0.9250 - val_loss: 0.2335 - val_precision: 0.9327 - val_recall: 0.9421 - learning_rate: 5.0000e-04\n",
            "Epoch 51/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.2251 - precision: 0.9347 - recall: 0.9433 - val_accuracy: 0.9295 - val_loss: 0.2244 - val_precision: 0.9354 - val_recall: 0.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 52/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.2139 - precision: 0.9355 - recall: 0.9486 - val_accuracy: 0.9260 - val_loss: 0.2203 - val_precision: 0.9321 - val_recall: 0.9446 - learning_rate: 5.0000e-04\n",
            "Epoch 53/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.2360 - precision: 0.9316 - recall: 0.9432 - val_accuracy: 0.9245 - val_loss: 0.2241 - val_precision: 0.9327 - val_recall: 0.9413 - learning_rate: 5.0000e-04\n",
            "Epoch 54/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.2029 - precision: 0.9444 - recall: 0.9580 - val_accuracy: 0.9265 - val_loss: 0.2259 - val_precision: 0.9343 - val_recall: 0.9430 - learning_rate: 5.0000e-04\n",
            "Epoch 55/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9264 - loss: 0.2232 - precision: 0.9322 - recall: 0.9454 - val_accuracy: 0.9285 - val_loss: 0.2181 - val_precision: 0.9396 - val_recall: 0.9404 - learning_rate: 5.0000e-04\n",
            "Epoch 56/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.1970 - precision: 0.9446 - recall: 0.9548 - val_accuracy: 0.9320 - val_loss: 0.2192 - val_precision: 0.9349 - val_recall: 0.9522 - learning_rate: 5.0000e-04\n",
            "Epoch 57/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.2086 - precision: 0.9393 - recall: 0.9530 - val_accuracy: 0.9310 - val_loss: 0.2177 - val_precision: 0.9392 - val_recall: 0.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 58/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2101 - precision: 0.9339 - recall: 0.9511 - val_accuracy: 0.9320 - val_loss: 0.2174 - val_precision: 0.9385 - val_recall: 0.9480 - learning_rate: 5.0000e-04\n",
            "Epoch 59/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9392 - loss: 0.2115 - precision: 0.9489 - recall: 0.9493 - val_accuracy: 0.9280 - val_loss: 0.2135 - val_precision: 0.9338 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 60/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.2033 - precision: 0.9420 - recall: 0.9511 - val_accuracy: 0.9355 - val_loss: 0.2181 - val_precision: 0.9396 - val_recall: 0.9530 - learning_rate: 5.0000e-04\n",
            "Epoch 61/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9400 - loss: 0.1940 - precision: 0.9437 - recall: 0.9565 - val_accuracy: 0.9320 - val_loss: 0.2179 - val_precision: 0.9400 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 62/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.1972 - precision: 0.9393 - recall: 0.9536 - val_accuracy: 0.9325 - val_loss: 0.2156 - val_precision: 0.9400 - val_recall: 0.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 63/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.2046 - precision: 0.9406 - recall: 0.9492 - val_accuracy: 0.9315 - val_loss: 0.2134 - val_precision: 0.9313 - val_recall: 0.9555 - learning_rate: 5.0000e-04\n",
            "Epoch 64/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.1931 - precision: 0.9454 - recall: 0.9551 - val_accuracy: 0.9275 - val_loss: 0.2150 - val_precision: 0.9323 - val_recall: 0.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 65/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1969 - precision: 0.9400 - recall: 0.9563 - val_accuracy: 0.9270 - val_loss: 0.2186 - val_precision: 0.9329 - val_recall: 0.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 66/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9406 - loss: 0.1913 - precision: 0.9459 - recall: 0.9552 - val_accuracy: 0.9295 - val_loss: 0.2158 - val_precision: 0.9361 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 67/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1841 - precision: 0.9482 - recall: 0.9596 - val_accuracy: 0.9280 - val_loss: 0.2182 - val_precision: 0.9345 - val_recall: 0.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 68/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.2000 - precision: 0.9418 - recall: 0.9541 - val_accuracy: 0.9295 - val_loss: 0.2110 - val_precision: 0.9339 - val_recall: 0.9488 - learning_rate: 5.0000e-04\n",
            "Epoch 69/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9443 - loss: 0.1825 - precision: 0.9494 - recall: 0.9577 - val_accuracy: 0.9305 - val_loss: 0.2085 - val_precision: 0.9391 - val_recall: 0.9446 - learning_rate: 5.0000e-04\n",
            "Epoch 70/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1892 - precision: 0.9432 - recall: 0.9523 - val_accuracy: 0.9300 - val_loss: 0.2179 - val_precision: 0.9362 - val_recall: 0.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 71/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1942 - precision: 0.9478 - recall: 0.9581 - val_accuracy: 0.9315 - val_loss: 0.2233 - val_precision: 0.9407 - val_recall: 0.9446 - learning_rate: 5.0000e-04\n",
            "Epoch 72/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.1856 - precision: 0.9516 - recall: 0.9582 - val_accuracy: 0.9320 - val_loss: 0.2130 - val_precision: 0.9400 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 73/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.1853 - precision: 0.9438 - recall: 0.9567 - val_accuracy: 0.9320 - val_loss: 0.2126 - val_precision: 0.9371 - val_recall: 0.9497 - learning_rate: 5.0000e-04\n",
            "Epoch 74/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.1907 - precision: 0.9425 - recall: 0.9583 - val_accuracy: 0.9320 - val_loss: 0.2071 - val_precision: 0.9400 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 75/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9509 - loss: 0.1737 - precision: 0.9512 - recall: 0.9674 - val_accuracy: 0.9305 - val_loss: 0.2014 - val_precision: 0.9355 - val_recall: 0.9488 - learning_rate: 5.0000e-04\n",
            "Epoch 76/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1726 - precision: 0.9489 - recall: 0.9598 - val_accuracy: 0.9340 - val_loss: 0.2097 - val_precision: 0.9439 - val_recall: 0.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 77/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1825 - precision: 0.9447 - recall: 0.9563 - val_accuracy: 0.9350 - val_loss: 0.2073 - val_precision: 0.9470 - val_recall: 0.9438 - learning_rate: 5.0000e-04\n",
            "Epoch 78/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.1803 - precision: 0.9477 - recall: 0.9575 - val_accuracy: 0.9280 - val_loss: 0.2103 - val_precision: 0.9295 - val_recall: 0.9513 - learning_rate: 5.0000e-04\n",
            "Epoch 79/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1834 - precision: 0.9480 - recall: 0.9609 - val_accuracy: 0.9335 - val_loss: 0.2045 - val_precision: 0.9387 - val_recall: 0.9505 - learning_rate: 5.0000e-04\n",
            "Epoch 80/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.1797 - precision: 0.9495 - recall: 0.9625 - val_accuracy: 0.9370 - val_loss: 0.2030 - val_precision: 0.9479 - val_recall: 0.9463 - learning_rate: 5.0000e-04\n",
            "Epoch 81/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1720 - precision: 0.9515 - recall: 0.9593 - val_accuracy: 0.9335 - val_loss: 0.2095 - val_precision: 0.9344 - val_recall: 0.9555 - learning_rate: 5.0000e-04\n",
            "Epoch 82/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1837 - precision: 0.9467 - recall: 0.9646 - val_accuracy: 0.9300 - val_loss: 0.2086 - val_precision: 0.9405 - val_recall: 0.9421 - learning_rate: 5.0000e-04\n",
            "Epoch 83/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1805 - precision: 0.9483 - recall: 0.9590 - val_accuracy: 0.9335 - val_loss: 0.2072 - val_precision: 0.9476 - val_recall: 0.9404 - learning_rate: 5.0000e-04\n",
            "Epoch 84/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.1692 - precision: 0.9552 - recall: 0.9597 - val_accuracy: 0.9380 - val_loss: 0.2012 - val_precision: 0.9443 - val_recall: 0.9522 - learning_rate: 5.0000e-04\n",
            "Epoch 85/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1725 - precision: 0.9514 - recall: 0.9604 - val_accuracy: 0.9330 - val_loss: 0.2026 - val_precision: 0.9386 - val_recall: 0.9497 - learning_rate: 5.0000e-04\n",
            "Epoch 86/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.1758 - precision: 0.9468 - recall: 0.9600 - val_accuracy: 0.9320 - val_loss: 0.2030 - val_precision: 0.9407 - val_recall: 0.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 87/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.1638 - precision: 0.9574 - recall: 0.9627 - val_accuracy: 0.9325 - val_loss: 0.2079 - val_precision: 0.9379 - val_recall: 0.9497 - learning_rate: 5.0000e-04\n",
            "Epoch 88/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9448 - loss: 0.1784 - precision: 0.9433 - recall: 0.9655 - val_accuracy: 0.9350 - val_loss: 0.2111 - val_precision: 0.9432 - val_recall: 0.9480 - learning_rate: 5.0000e-04\n",
            "Epoch 89/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.1701 - precision: 0.9488 - recall: 0.9618 - val_accuracy: 0.9355 - val_loss: 0.2037 - val_precision: 0.9433 - val_recall: 0.9488 - learning_rate: 5.0000e-04\n",
            "Epoch 90/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.1742 - precision: 0.9527 - recall: 0.9569 - val_accuracy: 0.9315 - val_loss: 0.2118 - val_precision: 0.9422 - val_recall: 0.9430 - learning_rate: 5.0000e-04\n",
            "Epoch 91/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9465 - loss: 0.1777 - precision: 0.9525 - recall: 0.9580 - val_accuracy: 0.9330 - val_loss: 0.2053 - val_precision: 0.9460 - val_recall: 0.9413 - learning_rate: 5.0000e-04\n",
            "Epoch 92/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1618 - precision: 0.9533 - recall: 0.9623 - val_accuracy: 0.9345 - val_loss: 0.2097 - val_precision: 0.9425 - val_recall: 0.9480 - learning_rate: 5.0000e-04\n",
            "Epoch 93/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1657 - precision: 0.9534 - recall: 0.9641 - val_accuracy: 0.9290 - val_loss: 0.2110 - val_precision: 0.9332 - val_recall: 0.9488 - learning_rate: 5.0000e-04\n",
            "Epoch 94/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1720 - precision: 0.9485 - recall: 0.9655 - val_accuracy: 0.9315 - val_loss: 0.2071 - val_precision: 0.9349 - val_recall: 0.9513 - learning_rate: 5.0000e-04\n",
            "Epoch 95/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9487 - loss: 0.1697 - precision: 0.9491 - recall: 0.9658 - val_accuracy: 0.9330 - val_loss: 0.2042 - val_precision: 0.9416 - val_recall: 0.9463 - learning_rate: 2.5000e-04\n",
            "Epoch 96/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1628 - precision: 0.9549 - recall: 0.9610 - val_accuracy: 0.9370 - val_loss: 0.1982 - val_precision: 0.9442 - val_recall: 0.9505 - learning_rate: 2.5000e-04\n",
            "Epoch 97/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1584 - precision: 0.9578 - recall: 0.9677 - val_accuracy: 0.9320 - val_loss: 0.2062 - val_precision: 0.9393 - val_recall: 0.9471 - learning_rate: 2.5000e-04\n",
            "Epoch 98/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1537 - precision: 0.9563 - recall: 0.9668 - val_accuracy: 0.9325 - val_loss: 0.2061 - val_precision: 0.9415 - val_recall: 0.9455 - learning_rate: 2.5000e-04\n",
            "Epoch 99/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1509 - precision: 0.9574 - recall: 0.9671 - val_accuracy: 0.9300 - val_loss: 0.2056 - val_precision: 0.9413 - val_recall: 0.9413 - learning_rate: 2.5000e-04\n",
            "Epoch 100/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1535 - precision: 0.9571 - recall: 0.9660 - val_accuracy: 0.9310 - val_loss: 0.2078 - val_precision: 0.9444 - val_recall: 0.9396 - learning_rate: 2.5000e-04\n",
            "Epoch 101/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1514 - precision: 0.9566 - recall: 0.9715 - val_accuracy: 0.9285 - val_loss: 0.2087 - val_precision: 0.9396 - val_recall: 0.9404 - learning_rate: 2.5000e-04\n",
            "Epoch 102/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1516 - precision: 0.9594 - recall: 0.9684 - val_accuracy: 0.9310 - val_loss: 0.2115 - val_precision: 0.9451 - val_recall: 0.9388 - learning_rate: 2.5000e-04\n",
            "Epoch 103/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1545 - precision: 0.9564 - recall: 0.9670 - val_accuracy: 0.9345 - val_loss: 0.1986 - val_precision: 0.9447 - val_recall: 0.9455 - learning_rate: 2.5000e-04\n",
            "Epoch 104/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9602 - loss: 0.1506 - precision: 0.9622 - recall: 0.9715 - val_accuracy: 0.9305 - val_loss: 0.2033 - val_precision: 0.9413 - val_recall: 0.9421 - learning_rate: 2.5000e-04\n",
            "Epoch 105/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1548 - precision: 0.9599 - recall: 0.9677 - val_accuracy: 0.9310 - val_loss: 0.2025 - val_precision: 0.9429 - val_recall: 0.9413 - learning_rate: 2.5000e-04\n",
            "Epoch 106/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1486 - precision: 0.9590 - recall: 0.9713 - val_accuracy: 0.9340 - val_loss: 0.2022 - val_precision: 0.9461 - val_recall: 0.9430 - learning_rate: 2.5000e-04\n",
            "Epoch 107/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1362 - precision: 0.9650 - recall: 0.9717 - val_accuracy: 0.9315 - val_loss: 0.2034 - val_precision: 0.9437 - val_recall: 0.9413 - learning_rate: 1.2500e-04\n",
            "Epoch 108/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1365 - precision: 0.9623 - recall: 0.9709 - val_accuracy: 0.9315 - val_loss: 0.2050 - val_precision: 0.9399 - val_recall: 0.9455 - learning_rate: 1.2500e-04\n",
            "Epoch 109/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1430 - precision: 0.9623 - recall: 0.9723 - val_accuracy: 0.9300 - val_loss: 0.2036 - val_precision: 0.9391 - val_recall: 0.9438 - learning_rate: 1.2500e-04\n",
            "Epoch 110/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1484 - precision: 0.9586 - recall: 0.9689 - val_accuracy: 0.9320 - val_loss: 0.2027 - val_precision: 0.9400 - val_recall: 0.9463 - learning_rate: 1.2500e-04\n",
            "Epoch 111/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1390 - precision: 0.9630 - recall: 0.9711 - val_accuracy: 0.9330 - val_loss: 0.2033 - val_precision: 0.9430 - val_recall: 0.9446 - learning_rate: 1.2500e-04\n",
            "Epoch 112/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1426 - precision: 0.9591 - recall: 0.9680 - val_accuracy: 0.9330 - val_loss: 0.2012 - val_precision: 0.9430 - val_recall: 0.9446 - learning_rate: 1.2500e-04\n",
            "Epoch 113/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1384 - precision: 0.9631 - recall: 0.9715 - val_accuracy: 0.9330 - val_loss: 0.1988 - val_precision: 0.9445 - val_recall: 0.9430 - learning_rate: 1.2500e-04\n",
            "Epoch 114/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1504 - precision: 0.9583 - recall: 0.9668 - val_accuracy: 0.9320 - val_loss: 0.2029 - val_precision: 0.9437 - val_recall: 0.9421 - learning_rate: 1.2500e-04\n",
            "Epoch 115/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1467 - precision: 0.9647 - recall: 0.9720 - val_accuracy: 0.9300 - val_loss: 0.2046 - val_precision: 0.9428 - val_recall: 0.9396 - learning_rate: 1.2500e-04\n",
            "Epoch 116/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1510 - precision: 0.9576 - recall: 0.9719 - val_accuracy: 0.9300 - val_loss: 0.2024 - val_precision: 0.9405 - val_recall: 0.9421 - learning_rate: 1.2500e-04\n",
            "Epoch 117/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1430 - precision: 0.9601 - recall: 0.9690 - val_accuracy: 0.9310 - val_loss: 0.2029 - val_precision: 0.9399 - val_recall: 0.9446 - learning_rate: 6.2500e-05\n",
            "Epoch 118/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.1378 - precision: 0.9641 - recall: 0.9745 - val_accuracy: 0.9330 - val_loss: 0.2031 - val_precision: 0.9423 - val_recall: 0.9455 - learning_rate: 6.2500e-05\n",
            "Epoch 119/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1416 - precision: 0.9601 - recall: 0.9729 - val_accuracy: 0.9305 - val_loss: 0.2025 - val_precision: 0.9413 - val_recall: 0.9421 - learning_rate: 6.2500e-05\n",
            "Epoch 120/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.1323 - precision: 0.9652 - recall: 0.9768 - val_accuracy: 0.9330 - val_loss: 0.2026 - val_precision: 0.9423 - val_recall: 0.9455 - learning_rate: 6.2500e-05\n",
            "Epoch 121/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1413 - precision: 0.9618 - recall: 0.9721 - val_accuracy: 0.9320 - val_loss: 0.2012 - val_precision: 0.9430 - val_recall: 0.9430 - learning_rate: 6.2500e-05\n",
            "Epoch 122/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1340 - precision: 0.9634 - recall: 0.9748 - val_accuracy: 0.9320 - val_loss: 0.2003 - val_precision: 0.9407 - val_recall: 0.9455 - learning_rate: 6.2500e-05\n",
            "Epoch 123/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.1305 - precision: 0.9654 - recall: 0.9749 - val_accuracy: 0.9325 - val_loss: 0.2016 - val_precision: 0.9430 - val_recall: 0.9438 - learning_rate: 6.2500e-05\n",
            "Epoch 124/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.1346 - precision: 0.9642 - recall: 0.9752 - val_accuracy: 0.9315 - val_loss: 0.2031 - val_precision: 0.9429 - val_recall: 0.9421 - learning_rate: 6.2500e-05\n",
            "Epoch 125/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1358 - precision: 0.9642 - recall: 0.9738 - val_accuracy: 0.9310 - val_loss: 0.2030 - val_precision: 0.9421 - val_recall: 0.9421 - learning_rate: 6.2500e-05\n",
            "Epoch 126/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1306 - precision: 0.9652 - recall: 0.9725 - val_accuracy: 0.9310 - val_loss: 0.2015 - val_precision: 0.9406 - val_recall: 0.9438 - learning_rate: 6.2500e-05\n",
            "Epoch 127/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1443 - precision: 0.9612 - recall: 0.9686 - val_accuracy: 0.9310 - val_loss: 0.2017 - val_precision: 0.9414 - val_recall: 0.9430 - learning_rate: 3.1250e-05\n",
            "Epoch 128/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1389 - precision: 0.9594 - recall: 0.9737 - val_accuracy: 0.9315 - val_loss: 0.2024 - val_precision: 0.9422 - val_recall: 0.9430 - learning_rate: 3.1250e-05\n",
            "Epoch 129/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1323 - precision: 0.9622 - recall: 0.9768 - val_accuracy: 0.9305 - val_loss: 0.2016 - val_precision: 0.9406 - val_recall: 0.9430 - learning_rate: 3.1250e-05\n",
            "Epoch 130/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.1376 - precision: 0.9645 - recall: 0.9726 - val_accuracy: 0.9305 - val_loss: 0.2011 - val_precision: 0.9421 - val_recall: 0.9413 - learning_rate: 3.1250e-05\n",
            "Epoch 131/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1321 - precision: 0.9661 - recall: 0.9736 - val_accuracy: 0.9290 - val_loss: 0.2011 - val_precision: 0.9404 - val_recall: 0.9404 - learning_rate: 3.1250e-05\n",
            "Epoch 132/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1275 - precision: 0.9684 - recall: 0.9709 - val_accuracy: 0.9290 - val_loss: 0.2016 - val_precision: 0.9404 - val_recall: 0.9404 - learning_rate: 3.1250e-05\n",
            "Epoch 133/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.1285 - precision: 0.9661 - recall: 0.9734 - val_accuracy: 0.9310 - val_loss: 0.2009 - val_precision: 0.9421 - val_recall: 0.9421 - learning_rate: 3.1250e-05\n",
            "Epoch 134/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9639 - loss: 0.1309 - precision: 0.9617 - recall: 0.9785 - val_accuracy: 0.9320 - val_loss: 0.2015 - val_precision: 0.9422 - val_recall: 0.9438 - learning_rate: 3.1250e-05\n",
            "Epoch 135/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1273 - precision: 0.9631 - recall: 0.9759 - val_accuracy: 0.9310 - val_loss: 0.2028 - val_precision: 0.9429 - val_recall: 0.9413 - learning_rate: 3.1250e-05\n",
            "Epoch 136/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1385 - precision: 0.9593 - recall: 0.9731 - val_accuracy: 0.9325 - val_loss: 0.2026 - val_precision: 0.9430 - val_recall: 0.9438 - learning_rate: 3.1250e-05\n",
            "Epoch 137/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1305 - precision: 0.9636 - recall: 0.9752 - val_accuracy: 0.9325 - val_loss: 0.2015 - val_precision: 0.9430 - val_recall: 0.9438 - learning_rate: 1.5625e-05\n",
            "Epoch 138/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9586 - loss: 0.1332 - precision: 0.9612 - recall: 0.9697 - val_accuracy: 0.9325 - val_loss: 0.2017 - val_precision: 0.9423 - val_recall: 0.9446 - learning_rate: 1.5625e-05\n",
            "Epoch 139/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1369 - precision: 0.9617 - recall: 0.9735 - val_accuracy: 0.9330 - val_loss: 0.2013 - val_precision: 0.9423 - val_recall: 0.9455 - learning_rate: 1.5625e-05\n",
            "Epoch 140/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1295 - precision: 0.9644 - recall: 0.9722 - val_accuracy: 0.9320 - val_loss: 0.2013 - val_precision: 0.9415 - val_recall: 0.9446 - learning_rate: 1.5625e-05\n",
            "Epoch 141/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1410 - precision: 0.9587 - recall: 0.9755 - val_accuracy: 0.9330 - val_loss: 0.2013 - val_precision: 0.9430 - val_recall: 0.9446 - learning_rate: 1.5625e-05\n",
            "Epoch 142/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1316 - precision: 0.9640 - recall: 0.9743 - val_accuracy: 0.9325 - val_loss: 0.2013 - val_precision: 0.9430 - val_recall: 0.9438 - learning_rate: 1.5625e-05\n",
            "Epoch 143/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1370 - precision: 0.9642 - recall: 0.9741 - val_accuracy: 0.9335 - val_loss: 0.2012 - val_precision: 0.9438 - val_recall: 0.9446 - learning_rate: 1.5625e-05\n",
            "Epoch 144/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.1259 - precision: 0.9640 - recall: 0.9771 - val_accuracy: 0.9330 - val_loss: 0.2021 - val_precision: 0.9438 - val_recall: 0.9438 - learning_rate: 1.5625e-05\n",
            "Epoch 145/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1439 - precision: 0.9622 - recall: 0.9680 - val_accuracy: 0.9320 - val_loss: 0.2022 - val_precision: 0.9422 - val_recall: 0.9438 - learning_rate: 1.5625e-05\n",
            "Epoch 146/150\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1365 - precision: 0.9640 - recall: 0.9707 - val_accuracy: 0.9330 - val_loss: 0.2023 - val_precision: 0.9438 - val_recall: 0.9438 - learning_rate: 1.5625e-05\n",
            "\n",
            "验证集结果:\n",
            "准确率: 0.9370\n",
            "精确率: 0.9442\n",
            "召回率: 0.9505\n",
            "预测概率: 0.9989（是1） -> 判断: 1\n",
            "预测概率: 0.9998（是1） -> 判断: 1\n",
            "预测概率: 0.9938（是1） -> 判断: 1\n",
            "预测概率: 0.9963（是1） -> 判断: 1\n",
            "预测概率: 0.9988（是1） -> 判断: 1\n",
            "预测概率: 0.7541（是1） -> 判断: 1\n",
            "预测概率: 1.0000（是1） -> 判断: 1\n",
            "预测概率: 0.7072（是1） -> 判断: 1\n",
            "预测概率: 0.9993（是1） -> 判断: 1\n",
            "预测概率: 0.9980（是1） -> 判断: 1\n",
            "预测概率: 0.0002（不是1） -> 判断: 3\n",
            "预测概率: 0.0060（不是1） -> 判断: 3\n",
            "预测概率: 0.2216（不是1） -> 判断: 3\n",
            "预测概率: 0.0160（不是1） -> 判断: 3\n",
            "预测概率: 0.0005（不是1） -> 判断: 3\n",
            "预测概率: 0.0189（不是1） -> 判断: 3\n",
            "预测概率: 0.0516（不是1） -> 判断: 3\n",
            "预测概率: 0.0003（不是1） -> 判断: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "预测概率: 0.0001（不是1） -> 判断: 3\n",
            "预测概率: 0.0003（不是1） -> 判断: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_edff6641-93ef-4a56-9137-c07a37a33963\", \"model.h5\", 141696)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}